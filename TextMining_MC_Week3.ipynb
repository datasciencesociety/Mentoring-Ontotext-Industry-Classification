{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly Challenge May 2019 - The Ontotext Case ðŸ’¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.The Ontotext Case - Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dill\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Data vizualizations\n",
    "import plotly\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot \n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.load_session('Week2_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range = (1,1), # only unigrams will be used\n",
    "                             max_df = 0.90, # any word appearing in more than 90% of the sample will be discarded\n",
    "                             max_features = 5000,\n",
    "                             binary = True # if we want features to be binary (the default is counts)  \n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(train.descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names()  # list of extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Extracted features (in alphabetical order)')\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV.The Ontotext Case - Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "FS_results = []\n",
    "vocabulary = []\n",
    "for cat in categories:\n",
    "    mi = mutual_info_classif(X_train, train.industry1 == cat, discrete_features=True, random_state = 42)\n",
    "    indices = np.argsort(mi) # get the indices of features\n",
    "    feature_names = np.array(vectorizer.get_feature_names())[indices] # get the features' names\n",
    "    values = mi[indices]\n",
    "    # Create a dataframe with the most important 20 features in each class\n",
    "    df = pd.DataFrame(list(reversed(feature_names))[:20], columns = ['feature'])\n",
    "    df['MI value'] = list(reversed(values))[:20]\n",
    "    df['Category'] = cat\n",
    "    FS_results.append(df)\n",
    "    vocabulary.append(list(reversed(feature_names))[:20]) # save all the features in a separate list \n",
    "    \n",
    "end = time.time()\n",
    "execution_time = end - start\n",
    "print(datetime.timedelta(seconds=execution_time)) # ~ 0:49:47.837228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS_results[:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Table(header=dict(values=['Word', 'MI Value', 'Category'],\n",
    "                             fill = dict(color=['#da80ec']), \n",
    "                             align = ['left'] * 5),\n",
    "                 cells=dict(values=[FS_results[1].feature.head(10), FS_results[1]['MI value'].head(10), FS_results[1].Category.head(10)], \n",
    "                            align = ['left'] * 5))\n",
    "\n",
    "layout = go.Layout(title='Feature importance by category',\n",
    "                   titlefont = dict(size = 20),\n",
    "                   width=500, height=500, \n",
    "                   paper_bgcolor =  'rgba(0,0,0,0)',\n",
    "                   plot_bgcolor = 'rgba(0,0,0,0)'\n",
    "                   )\n",
    "data = [trace]\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some findings after analyzing the results: \n",
    "\n",
    "- Generally speaking, our feature selection procedure managed to pick up terms that definitely seem relevant to the respective categories.\n",
    "- In almost all of the target classes we can find more specialized (associated directly with the category) terms. However, in a few of the categories we find mainly broad terms â€“ â€˜Marketingâ€™, â€˜Conglomerate_(company)â€™ and â€˜Commercial_and_professional_ servicesâ€™.\n",
    "- There are a lot of terms having the same root (manufacture-manufacturer-manufacturing) or terms appearing in both singular and plural form (school-schools). However, in most of these cases the terms have roughly the same meaning, so having them presented in so many different forms may add unnecessary noise in data. In such cases, stemming and lemmatization techniques may be applied in order to normalize the data.\n",
    "- There are certain broad terms that appear in most of the target classes â€“ ex. â€˜companyâ€™, â€™servicesâ€™, â€™firmâ€™, â€˜productsâ€™. This may lead to loss of discriminative power.\n",
    "- The word â€˜manufactureâ€™ or its derivatives appears to be one of the most important terms in several categories â€“ â€˜Manufacturingâ€™, â€˜Aerospace_and_defenseâ€™, â€˜Chemical_industryâ€™, â€˜Engineeringâ€™, â€˜Metalâ€™ and â€˜Automotiveâ€™. Its appearance in the mentioned categories makes sense but will probably lead to loss of discriminative power and high number of misclassifications between these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary[0:2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_set = []\n",
    "for featureset in vocabulary:\n",
    "    for term in featureset:\n",
    "        vocabulary_set.append(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_set = list(sorted(set(vocabulary_set))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocabulary_set) # 410 unique words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('Week3_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
